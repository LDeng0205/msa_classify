{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### replicate results of EVmutation with the PABP_YEAST dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from model import CouplingsModel\n",
    "import tools\n",
    "import scipy\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "# biopython SeqIO\n",
    "from Bio import SeqIO\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import scipy\n",
    "from collections import OrderedDict\n",
    "from sklearn.svm import OneClassSVM\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHABET_PROTEIN = '-ACDEFGHIKLMNPQRSTVWY'\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def encode(seqs, alphabet=ALPHABET_PROTEIN):\n",
    "    '''\n",
    "    Go from letters to numbers\n",
    "    '''\n",
    "    aa_to_i = OrderedDict((aa, i) for i, aa in enumerate( alphabet ))\n",
    "    X = np.asarray([[aa_to_i[x] for x in seq] \n",
    "                    for seq in seqs])\n",
    "    return X, aa_to_i\n",
    "def one_hot_encode(s):\n",
    "    return np.vstack([np.zeros(20), np.eye(20)])[s].flatten()\n",
    "\n",
    "def check_sequence(s, alphabet=ALPHABET_PROTEIN):\n",
    "    for aa in s:\n",
    "        if aa not in ALPHABET_PROTEIN:\n",
    "            return False\n",
    "    return True\n",
    "def process_msa_sequence(msa_sequences):\n",
    "    ''' takes in list of sequences and one-hot encodes the sequences'''\n",
    "    pos_upper = [x for x in range(len(msa_sequences[0])) if not msa_sequences[0][x].islower()]\n",
    "    msa_sequences = np.asarray([np.asarray(list(s))[pos_upper] for s in msa_sequences if not 'x' in s])\n",
    "    msa_sequences = np.asarray([s for s in msa_sequences if check_sequence(s) and len(s)==82])\n",
    "    msa_sequences = np.asarray(msa_sequences)\n",
    "\n",
    "    seqs_enc, aa_to_i = encode(msa_sequences)\n",
    "    oh_enc_seq = []\n",
    "    for s in seqs_enc:\n",
    "        oh_enc_seq.append(one_hot_encode(s))\n",
    "    oh_enc_seq = np.asarray(oh_enc_seq)\n",
    "    return oh_enc_seq\n",
    "\n",
    "def valid_weights_from_model(c):\n",
    "    ### returns only valid weights\n",
    "    _w = c.weights\n",
    "    _w_valid = []\n",
    "    for i in range(c.weights.shape[0]):\n",
    "        if _w[i] == 0: \n",
    "            continue\n",
    "        _w_valid.append(1/_w[i])\n",
    "    return _w_valid\n",
    "\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get all available msa sequences\n",
    "yeast_seq_str = []\n",
    "fasta_sequences = SeqIO.parse(open(\"PABP_YEAST/data/PABP_YEAST.a2m\"),'fasta')\n",
    "for fasta in fasta_sequences:\n",
    "    yeast_seq_str.append(str(fasta.seq))\n",
    "\n",
    "processed = process_msa_sequence(yeast_seq_str)\n",
    "c = CouplingsModel(f\"PABP_YEAST/model/PABP_YEAST.model_params\")\n",
    "weights = valid_weights_from_model(c)\n",
    "assert len(weights) == len(processed)\n",
    "wildtype_processed, wildtype_weights = processed[0], weights[0]\n",
    "processed, weights = np.asarray(processed[1:]), np.asarray(weights[1:])\n",
    "processed, weights = unison_shuffled_copies(processed, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1188, 1640)\n"
     ]
    }
   ],
   "source": [
    "# using the trained svm model on DMS data\n",
    "wildtype = yeast_seq_str[0]\n",
    "data = pd.read_csv(\n",
    "    \"PABP_YEAST/data/PABP_YEAST_Fields2013-singles.csv\", sep=\";\", comment=\"#\"\n",
    ")\n",
    "mutant, label = data['mutant'].to_numpy(), data['linear'].to_numpy()\n",
    "for i in range(label.shape[0]):\n",
    "    label[i] = 1 if label[i] > 0.7 else 0\n",
    "mutant_data = []\n",
    "for m in mutant:\n",
    "    original_aa, loc, mutant_aa = m[0], int(m[1:4])-115, m[4]\n",
    "    assert wildtype[loc] == original_aa\n",
    "    mutant_data.append(wildtype[:loc]+mutant_aa+wildtype[loc+1:])\n",
    "mutant_data = np.asarray(mutant_data)\n",
    "mutant_data = process_msa_sequence(mutant_data)\n",
    "\n",
    "mutant_data, label = np.asarray(mutant_data), np.asarray(label)\n",
    "mutant_data, label = unison_shuffled_copies(mutant_data, label)\n",
    "print(mutant_data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 1: Train a OneClassSVM with polynomial degree 2 kernel on MSA sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The classifier has some effect on MSA data. ~2700 out of 5000 total positive samples have been classified correctly from the MSA dataset\n",
    "\n",
    "clf = OneClassSVM(kernel='poly', degree=2, nu=0.3)\n",
    "train = processed[:50000]\n",
    "clf.fit(train, sample_weight=weights[:50000])\n",
    "pred = clf.predict(processed[50000:55000])\n",
    "print(pred[np.where(pred==1)].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/arthur/dev/msa_classify/svm_yeast.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bwhale.bair.berkeley.edu/home/arthur/dev/msa_classify/svm_yeast.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m mutant_pred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(mutant_data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "### The classifier does shitty job for mutant sequences (DMS).\n",
    "mutant_pred = clf.predict(mutant_data)\n",
    "print(pred[np.where(mutant_pred==1)].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 2: Train a OneClassSVM with polynomial degree 2 kernel on DMS sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/arthur/dev/msa_classify/svm_yeast.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bwhale.bair.berkeley.edu/home/arthur/dev/msa_classify/svm_yeast.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m pred[np\u001b[39m.\u001b[39mwhere(mutant_pred\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m)]\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "### also does a shitty job. Probably because too many features and did not shuffle sequences.\n",
    "import sklearn\n",
    "clf2 = sklearn.svm.SVC(kernel='poly', degree=2)\n",
    "split = mutant_data.shape[0]//5 * 4\n",
    "mut_train = mutant_data[:split]\n",
    "mut_test = mutant_data[split:]\n",
    "clf2.fit(mut_train, label[:split])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiement 3: Gaussian Kernel OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3552,)\n"
     ]
    }
   ],
   "source": [
    "clf = OneClassSVM(kernel='rbf', nu=0.3)\n",
    "train = processed[:50000]\n",
    "clf.fit(train, sample_weight=weights[:50000])\n",
    "pred = clf.predict(processed[50000:55000])\n",
    "print(pred[np.where(pred==1)].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1188,)\n"
     ]
    }
   ],
   "source": [
    "### The classifier does shitty job for mutant sequences (DMS).\n",
    "mutant_pred = clf.predict(mutant_data)\n",
    "print(pred[np.where(mutant_pred==1)].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiement 4: explicitly model pairwise features. the original d features become d^2 features. SVM still uses poly deg-2 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = processed.shape[1]\n",
    "num_seq = processed.shape[0]\n",
    "rich_msa = np.zeros((num_seq//10, d**2))\n",
    "\n",
    "# scipy.sparse.csr_matrix((num_seq, d**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicitly model pairwise interactions as features. This cell takes more than 1 hour to run\n",
    "for seq in range(num_seq//10):\n",
    "    for i in range(d):\n",
    "        for j in range(i, d):\n",
    "            if processed[seq][i] == 1 and processed[seq][j] == 1 or i == j:\n",
    "                rich_msa[seq][i*d + j] = 1\n",
    "rich_msa = scipy.sparse.csr_matrix(rich_msa, (num_seq//10, d**2))\n",
    "\n",
    "test = np.zeros((mutant_data.shape[0], d**2))\n",
    "for seq in range(mutant_data.shape[0]):\n",
    "    for i in range(d):\n",
    "        for j in range(i, d):\n",
    "            if mutant_data[seq][i] == 1 and mutant_data[seq][j] == 1 or i == j:\n",
    "                test[seq][i*d + j] = 1\n",
    "\n",
    "test_sparse = scipy.sparse.csr_matrix(test, (mutant_data.shape[0], d**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# with open(\"store_rich_msa.obj\", \"wb\") as file:\n",
    "#     pickle.dump(rich_msa, file)\n",
    "\n",
    "# with open(\"store_rich_test.obj\", \"wb\") as file:\n",
    "#     pickle.dump(test_sparse, file)\n",
    "\n",
    "# with open(\"store_rich_weights.obj\", \"wb\") as file:\n",
    "#     pickle.dump(weights, file)\n",
    "\n",
    "# with open(\"store_test_label.obj\", \"wb\") as file:\n",
    "#     pickle.dump(label, file)\n",
    "\n",
    "rich_msa, test_sparse = None, None\n",
    "label, weights = None, None\n",
    "with open(\"store_rich_msa.obj\", \"rb\") as file:\n",
    "    rich_msa = pickle.load(file)\n",
    "\n",
    "with open(\"store_rich_test.obj\", \"rb\") as file:\n",
    "    test_sparse = pickle.load(file)\n",
    "\n",
    "with open(\"store_rich_weights.obj\", \"rb\") as file:\n",
    "    weights = pickle.load(file)\n",
    "\n",
    "with open(\"store_test_label.obj\", \"rb\") as file:\n",
    "    label = pickle.load(file)\n",
    "    \n",
    "assert rich_msa.shape[1] == test_sparse.shape[1]\n",
    "assert label.shape[0] == test_sparse.shape[0]\n",
    "\n",
    "# ### expand wildtype\n",
    "wt = [0 for _ in range(d**2)]\n",
    "for i in range(d):\n",
    "    for j in range(i, d):\n",
    "        if wildtype_processed[i] == 1 and wildtype_processed[j] == 1 or i == j:\n",
    "            wt[i*d + j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n in [0.1, 0.15, 0.2, 0.25, 0.3]:\n",
    "#     clf = OneClassSVM(kernel='linear', nu=n)\n",
    "#     clf.fit(rich_msa, sample_weight=weights[:rich_msa.shape[0]])\n",
    "#     pred = clf.predict(test_sparse)\n",
    "#     cnt = 0 \n",
    "#     for i in range(mutant_data.shape[0]):\n",
    "#         if (pred[i]== 1 and label[i] == 1) or (pred[i] == -1 and label[i] == 0):\n",
    "#             cnt += 1\n",
    "#     print(f'kernel: linear, nu: {n}, result: ', cnt)\n",
    "#     print('wt: ', clf.predict([wt]))\n",
    "\n",
    "# ### prediction of wildtype\n",
    "# wt = [0 for _ in range(d**2)]\n",
    "# for i in range(d):\n",
    "#     for j in range(i, d):\n",
    "#         if wildtype_processed[i] == 1 and wildtype_processed[j] == 1 or i == j:\n",
    "#             wt[i*d + j] = 1\n",
    "# clf.predict([wt])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 4.1: Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    for deg in [1, 2, 3]:\n",
    "        clf = OneClassSVM(kernel='poly', degree = deg, nu=n)\n",
    "        clf.fit(rich_msa, sample_weight=weights[:rich_msa.shape[0]])\n",
    "        pred = clf.predict(test_sparse)\n",
    "        cnt = 0 \n",
    "        for i in range(mutant_data.shape[0]):\n",
    "            if (pred[i]== 1 and label[i] == 1) or (pred[i] == -1 and label[i] == 0):\n",
    "                cnt += 1\n",
    "        print(f'kernel: poly, degree: {deg}, nu: {n}, result: ', cnt)\n",
    "        print(pred[:20])\n",
    "        print(\"wild type pred: \", clf.predict([wt]))\n",
    "    \n",
    "    clf = OneClassSVM(kernel='rbf', nu=n)\n",
    "    clf.fit(rich_msa, sample_weight=weights[:rich_msa.shape[0]])\n",
    "    pred = clf.predict(test_sparse)\n",
    "    cnt = 0 \n",
    "    for i in range(mutant_data.shape[0]):\n",
    "        if (pred[i]== 1 and label[i] == 1) or (pred[i] == -1 and label[i] == 0):\n",
    "            cnt += 1\n",
    "    \n",
    "    print(f'kernel: rbf, nu: {n}, result: ', cnt)\n",
    "    print(pred[:20])\n",
    "    print(\"wild type pred: \", clf.predict([wt]))\n",
    "\n",
    "    clf = OneClassSVM(kernel='sigmoid', nu=n)\n",
    "    clf.fit(rich_msa, sample_weight=weights[:rich_msa.shape[0]])\n",
    "    pred = clf.predict(test_sparse)\n",
    "    cnt = 0 \n",
    "    for i in range(mutant_data.shape[0]):\n",
    "        if (pred[i]== 1 and label[i] == 1) or (pred[i] == -1 and label[i] == 0):\n",
    "            cnt += 1\n",
    "    print(f'kernel: rbf, nu: {n}, result: ', cnt)\n",
    "    print(pred[:20])\n",
    "    print(\"wild type pred: \", clf.predict([wt]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "    Only (kernel = 'rbf', nu = 0.2) and (kernel = 'rbf', nu = 0.3) produced results in which the prediction of mutant sequences were not all 1's or all -1's. For nu = 0.2, 716 sequences were classified correctly. For nu = 0.3, 543 sequences were classified correctly. There are a total of 673 (pos) + 515 (neg) = 1188 sequences. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiement 4.2: Look into the weights assigned to each feature in the linear model, see if SVM has learned anything interesting about pairwise weights. Compare with the Potts model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82, 82, 20, 20)\n"
     ]
    }
   ],
   "source": [
    "NAME=\"PABP_YEAST\"\n",
    "# load parameters from file to create a pairwise model\n",
    "c = CouplingsModel(f\"PABP_YEAST/model/{NAME}.model_params\")\n",
    "\n",
    "potts_params = c.J_ij\n",
    "print(potts_params.shape)\n",
    "\n",
    "potts_weights_arr = np.zeros(2689600)\n",
    "for i in range(82):\n",
    "    for aa1 in range(20):\n",
    "        for j in range(i, 82):\n",
    "            for aa2 in range(20):\n",
    "                potts_weights_arr[(i*20 + aa1) * d + j*20 + aa2] = c.J_ij[i][j][aa1][aa2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel: linear, nu: 0.001, result:  673\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1188\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.001 is: SpearmanrResult(correlation=0.0799076641387388, pvalue=0.0)\n",
      "kernel: linear, nu: 0.002, result:  673\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1188\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.002 is: SpearmanrResult(correlation=0.07981870911144529, pvalue=0.0)\n",
      "kernel: linear, nu: 0.01, result:  673\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1188\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.01 is: SpearmanrResult(correlation=0.08089272402400162, pvalue=0.0)\n",
      "kernel: linear, nu: 0.02, result:  673\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1188\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.02 is: SpearmanrResult(correlation=0.08254206570403295, pvalue=0.0)\n",
      "kernel: linear, nu: 0.1, result:  673\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1188\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.1 is: SpearmanrResult(correlation=0.08719157913545321, pvalue=0.0)\n",
      "kernel: linear, nu: 0.2, result:  673\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1188\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.2 is: SpearmanrResult(correlation=0.09147003963081074, pvalue=0.0)\n",
      "kernel: linear, nu: 0.3, result:  673\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1188\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.3 is: SpearmanrResult(correlation=0.09224111918860103, pvalue=0.0)\n",
      "kernel: linear, nu: 0.4, result:  673\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1188\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.4 is: SpearmanrResult(correlation=0.0920427746204786, pvalue=0.0)\n",
      "kernel: linear, nu: 0.5, result:  673\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1188\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.5 is: SpearmanrResult(correlation=0.09173197909130713, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "# train a linear model, which should theoretically be similar to the potts model.\n",
    "\n",
    "with open('result.txt', 'a') as file:\n",
    "    date_time = datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "    file.write(date_time)\n",
    "    file.write('\\n\\n')\n",
    "    for n in [0.001, 0.002, 0.01, 0.02, 0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "        clf = OneClassSVM(kernel='linear', nu=n)\n",
    "        clf.fit(rich_msa, sample_weight=weights[:rich_msa.shape[0]])\n",
    "        pred = clf.predict(test_sparse)\n",
    "        cnt = 0 \n",
    "        for i in range(mutant_data.shape[0]):\n",
    "            if (pred[i]== 1 and label[i] == 1) or (pred[i] == -1 and label[i] == 0):\n",
    "                cnt += 1\n",
    "        print(f'kernel: linear, nu: {n}, result: ', cnt)\n",
    "        file.write(f'kernel: linear, nu: {n}, result: {cnt}\\n')\n",
    "        print(pred[:20])\n",
    "        file.write('\\n')\n",
    "        print(np.sum(pred))\n",
    "        file.write(f'Sum: {np.sum(pred)}\\n')\n",
    "        print(\"wild type pred: \", clf.predict([wt]))\n",
    "        file.write(f'wild type pred : {clf.predict([wt])}\\n')\n",
    "        w = clf.coef_.toarray()\n",
    "        w = w.flatten()\n",
    "\n",
    "        sprm = scipy.stats.spearmanr(w, potts_weights_arr)\n",
    "        print(f'spearman for nu = {n} is: {sprm}')\n",
    "        file.write(f'spearman for nu = {n} is: {sprm}\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel: rbf, nu: 0.001, result:  673\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1188\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.001 is: SpearmanrResult(correlation=0.08430774677159406, pvalue=0.0)\n",
      "kernel: rbf, nu: 0.002, result:  673\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1188\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.002 is: SpearmanrResult(correlation=0.08442035815768388, pvalue=0.0)\n",
      "kernel: rbf, nu: 0.01, result:  673\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1188\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.01 is: SpearmanrResult(correlation=0.08379710418208093, pvalue=0.0)\n",
      "kernel: rbf, nu: 0.02, result:  673\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1188\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.02 is: SpearmanrResult(correlation=0.08362051515625542, pvalue=0.0)\n",
      "kernel: rbf, nu: 0.1, result:  673\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1188\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.1 is: SpearmanrResult(correlation=0.08456227564812689, pvalue=0.0)\n",
      "kernel: rbf, nu: 0.2, result:  691\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1]\n",
      "1048\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.2 is: SpearmanrResult(correlation=0.08428860892944573, pvalue=0.0)\n",
      "kernel: rbf, nu: 0.201, result:  691\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1]\n",
      "1044\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.201 is: SpearmanrResult(correlation=0.08424957441155029, pvalue=0.0)\n",
      "kernel: rbf, nu: 0.202, result:  691\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1]\n",
      "1044\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.202 is: SpearmanrResult(correlation=0.08440367723427164, pvalue=0.0)\n",
      "kernel: rbf, nu: 0.21, result:  711\n",
      "[ 1  1  1 -1 -1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1]\n",
      "984\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.21 is: SpearmanrResult(correlation=0.0844394897724151, pvalue=0.0)\n",
      "kernel: rbf, nu: 0.22, result:  717\n",
      "[ 1  1  1 -1 -1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1]\n",
      "956\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.22 is: SpearmanrResult(correlation=0.0844291329007868, pvalue=0.0)\n",
      "kernel: rbf, nu: 0.28, result:  752\n",
      "[-1  1 -1 -1 -1 -1 -1  1  1  1 -1  1  1  1  1 -1  1  1  1  1]\n",
      "246\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.28 is: SpearmanrResult(correlation=0.08442733479666718, pvalue=0.0)\n",
      "kernel: rbf, nu: 0.3, result:  754\n",
      "[-1 -1 -1 -1 -1 -1 -1  1  1  1 -1  1  1  1  1 -1  1  1  1  1]\n",
      "-6\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.3 is: SpearmanrResult(correlation=0.08430788502873145, pvalue=0.0)\n",
      "kernel: rbf, nu: 0.5, result:  515\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "-1188\n",
      "wild type pred:  [-1]\n",
      "spearman for nu = 0.5 is: SpearmanrResult(correlation=0.08397174793930237, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "with open('result.txt', 'a') as file:\n",
    "    date_time = datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "    file.write(date_time)\n",
    "    file.write('\\n\\n')\n",
    "    # train a rbf model, which should theoretically be similar to the potts model.\n",
    "    for n in [0.001, 0.002, 0.01, 0.02, 0.1, 0.2, 0.201, 0.202, 0.21, 0.22, 0.28, 0.3, 0.5]:\n",
    "        clf = OneClassSVM(kernel='rbf', nu=n)\n",
    "        clf.fit(rich_msa, sample_weight=weights[:rich_msa.shape[0]])\n",
    "        pred = clf.predict(test_sparse)\n",
    "        cnt = 0 \n",
    "        for i in range(mutant_data.shape[0]):\n",
    "            if (pred[i]== 1 and label[i] == 1) or (pred[i] == -1 and label[i] == 0):\n",
    "                cnt += 1\n",
    "\n",
    "        print(f'kernel: rbf, nu: {n}, result: ', cnt)\n",
    "        file.write(f'kernel: rbf, nu: {n}, result: {cnt}\\n')\n",
    "        print(pred[:20])\n",
    "        print(np.sum(pred))\n",
    "        file.write(f'Sum: {np.sum(pred)}\\n')\n",
    "        print(\"wild type pred: \", clf.predict([wt]))\n",
    "        file.write(f'wild type pred : {clf.predict([wt])}\\n')\n",
    "        sv = clf.support_vectors_\n",
    "        c = clf.dual_coef_\n",
    "        w = (c @ sv).toarray().flatten()\n",
    "\n",
    "        sprm = scipy.stats.spearmanr(w, potts_weights_arr)\n",
    "        print(f'spearman for nu = {n} is: {sprm}')\n",
    "        file.write(f'spearman for nu = {n} is: {sprm}\\n\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel: poly-2, nu: 0.001, result:  673\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1188\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.001 is: SpearmanrResult(correlation=0.08426271678544617, pvalue=0.0)\n",
      "kernel: poly-2, nu: 0.002, result:  673\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1188\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.002 is: SpearmanrResult(correlation=0.08478842538701295, pvalue=0.0)\n",
      "kernel: poly-2, nu: 0.01, result:  673\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1188\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.01 is: SpearmanrResult(correlation=0.08578413116966253, pvalue=0.0)\n",
      "kernel: poly-2, nu: 0.02, result:  673\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1188\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.02 is: SpearmanrResult(correlation=0.08616116699946114, pvalue=0.0)\n",
      "kernel: poly-2, nu: 0.1, result:  673\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1188\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.1 is: SpearmanrResult(correlation=0.09002485120390699, pvalue=0.0)\n",
      "kernel: poly-2, nu: 0.2, result:  673\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1188\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.2 is: SpearmanrResult(correlation=0.09315350354521608, pvalue=0.0)\n",
      "kernel: poly-2, nu: 0.201, result:  673\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1188\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.201 is: SpearmanrResult(correlation=0.09312235929317621, pvalue=0.0)\n",
      "kernel: poly-2, nu: 0.202, result:  673\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1188\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.202 is: SpearmanrResult(correlation=0.0931510864040238, pvalue=0.0)\n",
      "kernel: poly-2, nu: 0.21, result:  673\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1188\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.21 is: SpearmanrResult(correlation=0.0930757804493768, pvalue=0.0)\n",
      "kernel: poly-2, nu: 0.22, result:  673\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1188\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.22 is: SpearmanrResult(correlation=0.09315576116703389, pvalue=0.0)\n",
      "kernel: poly-2, nu: 0.28, result:  673\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1188\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.28 is: SpearmanrResult(correlation=0.0928613362728432, pvalue=0.0)\n",
      "kernel: poly-2, nu: 0.3, result:  673\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1188\n",
      "wild type pred:  [1]\n",
      "spearman for nu = 0.3 is: SpearmanrResult(correlation=0.09268774915203934, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "with open('result.txt', 'a') as file:\n",
    "    date_time = datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "    file.write(date_time)\n",
    "    file.write('\\n\\n')\n",
    "    # train a rbf model, which should theoretically be similar to the potts model.\n",
    "    for n in [0.001, 0.002, 0.01, 0.02, 0.1, 0.2, 0.201, 0.202, 0.21, 0.22, 0.28, 0.3, 0.5]:\n",
    "        clf = OneClassSVM(kernel='poly', degree=2, nu=n)\n",
    "        clf.fit(rich_msa, sample_weight=weights[:rich_msa.shape[0]])\n",
    "        pred = clf.predict(test_sparse)\n",
    "        cnt = 0 \n",
    "        for i in range(mutant_data.shape[0]):\n",
    "            if (pred[i]== 1 and label[i] == 1) or (pred[i] == -1 and label[i] == 0):\n",
    "                cnt += 1\n",
    "\n",
    "        print(f'kernel: poly-2, nu: {n}, result: ', cnt)\n",
    "        file.write(f'kernel: poly-2, nu: {n}, result: {cnt}\\n')\n",
    "        print(pred[:20])\n",
    "        print(np.sum(pred))\n",
    "        file.write(f'Sum: {np.sum(pred)}\\n')\n",
    "        print(\"wild type pred: \", clf.predict([wt]))\n",
    "        file.write(f'wild type pred : {clf.predict([wt])}\\n')\n",
    "        sv = clf.support_vectors_\n",
    "        c = clf.dual_coef_\n",
    "        w = (c @ sv).toarray().flatten()\n",
    "\n",
    "        sprm = scipy.stats.spearmanr(w, potts_weights_arr)\n",
    "        print(f'spearman for nu = {n} is: {sprm}')\n",
    "        file.write(f'spearman for nu = {n} is: {sprm}\\n\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(472, 2689600)\n",
      "(1, 472)\n"
     ]
    }
   ],
   "source": [
    "print(sv.shape)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2689600,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman for nu = 0.001 is: SpearmanrResult(correlation=0.08430774677159406, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "# w = clf.coef_.toarray()\n",
    "# w = w.flatten()\n",
    "\n",
    "sprm = scipy.stats.spearmanr(w, potts_weights_arr)\n",
    "print(f'spearman for nu = {n} is: {sprm}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_arthur",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b975e03f1e86e078ea1d566012707067ac1f6e4c759ff48317f6f9dc08e1449"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
