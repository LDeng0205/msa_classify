{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### replicate results of EVmutation with the PABP_YEAST dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from model import CouplingsModel\n",
    "import tools\n",
    "import scipy\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "# biopython SeqIO\n",
    "from Bio import SeqIO\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import scipy\n",
    "from collections import OrderedDict\n",
    "from sklearn.svm import OneClassSVM\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHABET_PROTEIN = '-ACDEFGHIKLMNPQRSTVWY'\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def encode(seqs, alphabet=ALPHABET_PROTEIN):\n",
    "    '''\n",
    "    Go from letters to numbers\n",
    "    '''\n",
    "    aa_to_i = OrderedDict((aa, i) for i, aa in enumerate( alphabet ))\n",
    "    X = np.asarray([[aa_to_i[x] for x in seq] \n",
    "                    for seq in seqs])\n",
    "    return X, aa_to_i\n",
    "def one_hot_encode(s):\n",
    "    return np.vstack([np.zeros(20), np.eye(20)])[s].flatten()\n",
    "\n",
    "def check_sequence(s, alphabet=ALPHABET_PROTEIN):\n",
    "    for aa in s:\n",
    "        if aa not in ALPHABET_PROTEIN:\n",
    "            return False\n",
    "    return True\n",
    "def process_msa_sequence(msa_sequences):\n",
    "    ''' takes in list of sequences and one-hot encodes the sequences'''\n",
    "    pos_upper = [x for x in range(len(msa_sequences[0])) if not msa_sequences[0][x].islower()]\n",
    "    msa_sequences = np.asarray([np.asarray(list(s))[pos_upper] for s in msa_sequences if not 'x' in s])\n",
    "    msa_sequences = np.asarray([s for s in msa_sequences if check_sequence(s) and len(s)==82])\n",
    "    msa_sequences = np.asarray(msa_sequences)\n",
    "\n",
    "    seqs_enc, aa_to_i = encode(msa_sequences)\n",
    "    oh_enc_seq = []\n",
    "    for s in seqs_enc:\n",
    "        oh_enc_seq.append(one_hot_encode(s))\n",
    "    oh_enc_seq = np.asarray(oh_enc_seq)\n",
    "    return oh_enc_seq\n",
    "\n",
    "def valid_weights_from_model(c):\n",
    "    ### returns only valid weights\n",
    "    _w = c.weights\n",
    "    _w_valid = []\n",
    "    for i in range(c.weights.shape[0]):\n",
    "        if _w[i] == 0: \n",
    "            continue\n",
    "        _w_valid.append(1/_w[i])\n",
    "    return _w_valid\n",
    "    \n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert a.shape[0] == b.shape[0]\n",
    "    p = np.random.permutation(a.shape[0])\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get all available msa sequences\n",
    "yeast_seq_str = []\n",
    "fasta_sequences = SeqIO.parse(open(\"PABP_YEAST/data/PABP_YEAST.a2m\"),'fasta')\n",
    "for fasta in fasta_sequences:\n",
    "    yeast_seq_str.append(str(fasta.seq))\n",
    "\n",
    "processed = process_msa_sequence(yeast_seq_str)\n",
    "c = CouplingsModel(f\"PABP_YEAST/model/PABP_YEAST.model_params\")\n",
    "weights = valid_weights_from_model(c)\n",
    "assert len(weights) == len(processed)\n",
    "wildtype_processed, wildtype_weights = processed[0], weights[0]\n",
    "processed, weights = np.asarray(processed[1:]), np.asarray(weights[1:])\n",
    "processed, weights = unison_shuffled_copies(processed, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1188, 1640)\n"
     ]
    }
   ],
   "source": [
    "# using the trained svm model on DMS data\n",
    "wildtype = yeast_seq_str[0]\n",
    "data = pd.read_csv(\n",
    "    \"PABP_YEAST/data/PABP_YEAST_Fields2013-singles.csv\", sep=\";\", comment=\"#\"\n",
    ")\n",
    "mutant, label_dms = data['mutant'].to_numpy(), data['linear'].to_numpy()\n",
    "label = np.zeros(label_dms.shape[0])\n",
    "for i in range(label_dms.shape[0]):\n",
    "    label[i] = 1 if label_dms[i] > 0.7 else 0\n",
    "mutant_data = []\n",
    "for m in mutant:\n",
    "    original_aa, loc, mutant_aa = m[0], int(m[1:4])-115, m[4]\n",
    "    assert wildtype[loc] == original_aa\n",
    "    mutant_data.append(wildtype[:loc]+mutant_aa+wildtype[loc+1:])\n",
    "mutant_data = np.asarray(mutant_data)\n",
    "mutant_data = process_msa_sequence(mutant_data)\n",
    "\n",
    "mutant_data, label = np.asarray(mutant_data), np.asarray(label)\n",
    "mutant_data, label = unison_shuffled_copies(mutant_data, label)\n",
    "print(mutant_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(820,)\n",
      "kernel: poly deg 2, nu: 1.5e-06, result:  518\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "-1170\n",
      "(1203,)\n",
      "kernel: poly deg 2, nu: 1.52e-06, result:  743\n",
      "[-1  1 -1 -1 -1 -1 -1  1  1  1  1  1  1  1  1 -1  1  1  1  1]\n",
      "296\n",
      "(1203,)\n",
      "kernel: poly deg 2, nu: 1.53e-06, result:  743\n",
      "[-1  1 -1 -1 -1 -1 -1  1  1  1  1  1  1  1  1 -1  1  1  1  1]\n",
      "296\n",
      "(1203,)\n",
      "kernel: poly deg 2, nu: 1.54e-06, result:  743\n",
      "[-1  1 -1 -1 -1 -1 -1  1  1  1  1  1  1  1  1 -1  1  1  1  1]\n",
      "296\n",
      "(1671,)\n",
      "kernel: poly deg 2, nu: 1.56e-06, result:  702\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1]\n",
      "1054\n"
     ]
    }
   ],
   "source": [
    "# train a linear model, which should theoretically be similar to the potts model.\n",
    "\n",
    "with open('result.txt', 'a') as file:\n",
    "    file.write(\"Polynomial degree 2 kernel no expansion\")\n",
    "    date_time = datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "    file.write(date_time)\n",
    "    file.write('\\n\\n')\n",
    "    for n in [0.0000015, 0.00000152, 0.00000153, 0.00000154, 0.00000156]:\n",
    "        clf = OneClassSVM(kernel='poly', degree=2, nu=n)\n",
    "        clf.fit(processed[:140000], sample_weight=weights[:140000])\n",
    "        pred_msa = clf.predict(processed[140000:145000])\n",
    "        print(pred_msa[np.where(pred_msa==1)].shape)\n",
    "        pred = clf.predict(mutant_data)\n",
    "        cnt = 0 \n",
    "        for i in range(mutant_data.shape[0]):\n",
    "            if (pred[i]== 1 and label[i] == 1) or (pred[i] == -1 and label[i] == 0):\n",
    "                cnt += 1\n",
    "        print(f'kernel: poly deg 2, nu: {n}, result: ', cnt)\n",
    "        file.write(f'kernel: poly deg 2, nu: {n}, result: {cnt}\\n')\n",
    "        print(pred[:20])\n",
    "        file.write('\\n')\n",
    "        print(np.sum(pred))\n",
    "        file.write(f'Sum: {np.sum(pred)}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6254208754208754"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "743/1188"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_arthur",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b975e03f1e86e078ea1d566012707067ac1f6e4c759ff48317f6f9dc08e1449"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
